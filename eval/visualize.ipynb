{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030cbf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "data_dir = \"/media/george/Data/mustc/en-de\"\n",
    "code_dir = \"/home/george/Projects/simulst\"\n",
    "fair_dir = \"/home/george/utility/fairseq\"\n",
    "sys.path.insert(0, code_dir)\n",
    "sys.path.insert(0, fair_dir)\n",
    "model = \"cif_de_align_ctc0_3_lat0_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2815ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import examples.simultaneous_translation\n",
    "from fairseq import (\n",
    "    checkpoint_utils,\n",
    "    options,\n",
    "    quantization_utils,\n",
    "    tasks,\n",
    "    utils,\n",
    ")\n",
    "from torchinfo import summary\n",
    "import logging\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from fairseq_cli.generate import get_symbols_to_strip_from_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fb1387",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = f\"{code_dir}/exp/checkpoints/{model}/checkpoint_best.pt\"\n",
    "use_cuda = True\n",
    "\n",
    "overrides = {\n",
    "    \"user_dir\": f\"{code_dir}/codebase\",\n",
    "    \"inference_config_yaml\": f\"{code_dir}/exp/infer_st.yaml\",\n",
    "    \"data\": data_dir,\n",
    "    \"gen_subset\": \"tst-COMMON_st\",\n",
    "    \"batch_size\": 1,\n",
    "    \"beam\": 1,\n",
    "    \"do_mtl\": True,\n",
    "}\n",
    "\n",
    "states = checkpoint_utils.load_checkpoint_to_cpu(\n",
    "    path=checkpoint, arg_overrides=overrides, load_on_all_ranks=False)\n",
    "cfg = states[\"cfg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a074b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    level=os.environ.get(\"LOGLEVEL\", \"INFO\").upper(),\n",
    "    stream=sys.stdout,\n",
    ")\n",
    "logger = logging.getLogger(\"fairseq_cli.train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dcf942",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.import_user_module(cfg.common)\n",
    "\n",
    "# Setup task, e.g., translation, language modeling, etc.\n",
    "task = tasks.setup_task(cfg.task)\n",
    "# Build model and criterion\n",
    "model = task.build_model(cfg.model)\n",
    "criterion = task.build_criterion(cfg.criterion)\n",
    "logger.info(summary(model))\n",
    "logger.info(\"task: {}\".format(task.__class__.__name__))\n",
    "logger.info(\"model: {}\".format(model.__class__.__name__))\n",
    "logger.info(\"criterion: {}\".format(criterion.__class__.__name__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be2d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"loading model(s) from {}\".format(cfg.common_eval.path))\n",
    "model = task.build_model(cfg.model)\n",
    "model.load_state_dict(\n",
    "    states[\"model\"], strict=True, model_cfg=cfg.model\n",
    ")\n",
    "\n",
    "# Optimize ensemble for generation\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "model.prepare_for_inference_(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9167bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "task.load_dataset(cfg.dataset.gen_subset, task_cfg=cfg.task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd070f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset \n",
    "itr = task.get_batch_iterator(\n",
    "    dataset=task.dataset(cfg.dataset.gen_subset),\n",
    "    max_tokens=cfg.dataset.max_tokens,\n",
    "    max_sentences=cfg.dataset.batch_size,\n",
    "    max_positions=utils.resolve_max_positions(\n",
    "        task.max_positions(), model.max_positions() #*[m.max_positions() for m in models]\n",
    "    ),\n",
    "    ignore_invalid_inputs=cfg.dataset.skip_invalid_size_inputs_valid_test,\n",
    "    required_batch_size_multiple=cfg.dataset.required_batch_size_multiple,\n",
    "    seed=cfg.common.seed,\n",
    "    num_shards=cfg.distributed_training.distributed_world_size,\n",
    "    shard_id=cfg.distributed_training.distributed_rank,\n",
    "    num_workers=cfg.dataset.num_workers,\n",
    "    data_buffer_size=cfg.dataset.data_buffer_size,\n",
    ").next_epoch_itr(shuffle=False)\n",
    "\n",
    "generator = task.build_generator(\n",
    "    [model], cfg.generation,\n",
    ")\n",
    "\n",
    "# Handle tokenization and BPE\n",
    "src_dict = task.source_dictionary\n",
    "tgt_dict = task.target_dictionary\n",
    "tokenizer = task.build_tokenizer(cfg.tokenizer)\n",
    "bpe = task.build_bpe(cfg.bpe)\n",
    "\n",
    "def encode_fn(x):\n",
    "    if tokenizer is not None:\n",
    "        x = tokenizer.encode(x)\n",
    "    if bpe is not None:\n",
    "        x = bpe.encode(x)\n",
    "    return x\n",
    "\n",
    "def decode_fn(x):\n",
    "    if bpe is not None:\n",
    "        x = bpe.decode(x)\n",
    "    if tokenizer is not None:\n",
    "        x = tokenizer.decode(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980499ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2528\n",
    "for sample in itr:\n",
    "    if use_cuda:\n",
    "        sample = utils.move_to_cuda(sample) \n",
    "    hypo_tokens = utils.post_process_prediction(\n",
    "        sample[\"target\"][0].int().cpu(),\n",
    "        src_str=None,\n",
    "        alignment=None,\n",
    "        align_dict=None,\n",
    "        tgt_dict=tgt_dict,\n",
    "        remove_bpe=\"sentencepiece\",\n",
    "        extra_symbols_to_ignore=get_symbols_to_strip_from_output(generator),\n",
    "    )[1]\n",
    "    if \"Lassen Sie mich Ihnen zeigen,\" in hypo_tokens:\n",
    "        print(sample)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab5d940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 2529\n",
    "# for sample in itr:\n",
    "#     if use_cuda:\n",
    "#         sample = utils.move_to_cuda(sample) \n",
    "#     if \"net_input\" not in sample:\n",
    "#         continue\n",
    "#     if sample['id'].item() == idx:\n",
    "#         break\n",
    "# assert sample['id'].item() == idx\n",
    "sample_w_asr = sample\n",
    "sample = {\n",
    "    \"id\": sample_w_asr[\"id\"],\n",
    "    \"net_input\": {\n",
    "        \"src_tokens\": sample_w_asr[\"net_input\"][\"src_tokens\"],\n",
    "        \"src_lengths\": sample_w_asr[\"net_input\"][\"src_lengths\"],\n",
    "    }\n",
    "}\n",
    "translations = task.inference_step(\n",
    "    generator, [model], sample\n",
    ")\n",
    "utils.post_process_prediction(\n",
    "    hypo_tokens=translations[0][0][\"tokens\"].int().cpu(),\n",
    "    src_str=None,\n",
    "    alignment=None,\n",
    "    align_dict=None,\n",
    "    tgt_dict=tgt_dict,\n",
    "    remove_bpe=None, #\"sentencepiece\",\n",
    "    extra_symbols_to_ignore=get_symbols_to_strip_from_output(generator),\n",
    ")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d1aded",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.post_process_prediction(\n",
    "    hypo_tokens=translations[0][0][\"tokens\"].int().cpu(),\n",
    "    src_str=None,\n",
    "    alignment=None,\n",
    "    align_dict=None,\n",
    "    tgt_dict=tgt_dict,\n",
    "    remove_bpe=\"sentencepiece\",\n",
    "    extra_symbols_to_ignore=get_symbols_to_strip_from_output(generator),\n",
    ")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokens = sample[\"net_input\"][\"src_tokens\"]\n",
    "src_lengths = sample[\"net_input\"][\"src_lengths\"]\n",
    "target = translations[0][0][\"tokens\"].unsqueeze(0).type_as(src_lengths)\n",
    "prev_output_tokens = target.roll(1, 1)\n",
    "# logits, extra = model(src_tokens, src_lengths, prev_output_tokens=prev_output_tokens)\n",
    "extra = model.encoder(src_tokens, src_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cc82b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "gen_set = overrides['gen_subset'].replace('_st', '')\n",
    "with open(f\"/home/george/Projects/simulst/eval/data_de/{gen_set}.wav_list\", \"r\") as f:\n",
    "    for l in f:\n",
    "        paths.append(l.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14146cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_string = utils.post_process_prediction(\n",
    "    hypo_tokens=sample_w_asr['net_input']['src_txt_tokens'][0].int().cpu(),\n",
    "    src_str=None,\n",
    "    alignment=None,\n",
    "    align_dict=None,\n",
    "    tgt_dict=src_dict,\n",
    "    remove_bpe=\"sentencepiece\",\n",
    "    extra_symbols_to_ignore=get_symbols_to_strip_from_output(generator),\n",
    ")[1]\n",
    "paths[idx], asr_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4198bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import IPython\n",
    "wav, sr = torchaudio.load(paths[idx])\n",
    "IPython.display.Audio(wav[:,:], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7913e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = extra[\"alpha\"][0].detach()\n",
    "cif_steps = alpha.cumsum(-1).floor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ccce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_checkpoint = f\"{code_dir}/exp/checkpoints/ctc_s2s_asr_de/checkpoint_best.pt\"\n",
    "asr_states = checkpoint_utils.load_checkpoint_to_cpu(\n",
    "    path=asr_checkpoint, arg_overrides=overrides, load_on_all_ranks=False)\n",
    "asr_cfg = asr_states[\"cfg\"]\n",
    "# Setup task, e.g., translation, language modeling, etc.\n",
    "asr_task = tasks.setup_task(asr_cfg.task)\n",
    "# Build model and criterion\n",
    "asr_model = asr_task.build_model(asr_cfg.model)\n",
    "asr_model.load_state_dict(\n",
    "    asr_states[\"model\"], strict=True, model_cfg=asr_cfg.model\n",
    ")\n",
    "\n",
    "# Optimize ensemble for generation\n",
    "if use_cuda:\n",
    "    asr_model.cuda()\n",
    "asr_model.prepare_for_inference_(asr_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaad148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from codebase.criterion.best_alignment import best_alignment\n",
    "# encoder_out = asr_model.encoder(\n",
    "#     sample['net_input']['src_tokens'],\n",
    "#     sample['net_input']['src_lengths'],\n",
    "# )\n",
    "# ctc_logits = encoder_out[\"ctc_logits\"][0]\n",
    "# encoder_mask = encoder_out[\"encoder_padding_mask\"][0]\n",
    "# asr_target = sample_w_asr['net_input']['src_txt_tokens']\n",
    "# asr_lenths = sample_w_asr['net_input']['src_txt_lengths']\n",
    "\n",
    "# ctc_logits[..., 0] = ctc_logits[..., 0] - 10\n",
    "# states = best_alignment(\n",
    "#     ctc_logits.log_softmax(-1).transpose(0, 1),\n",
    "#     asr_target,\n",
    "#     (~encoder_mask).sum(-1),\n",
    "#     asr_lenths,\n",
    "#     blank=0,\n",
    "#     as_labels=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e89fdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfa = \"\"\"intervals [1]:\n",
    "            xmin = 0 \n",
    "            xmax = 0.03 \n",
    "            text = \"\" \n",
    "        intervals [2]:\n",
    "            xmin = 0.03 \n",
    "            xmax = 0.14 \n",
    "            text = \"let\" \n",
    "        intervals [3]:\n",
    "            xmin = 0.14 \n",
    "            xmax = 0.26 \n",
    "            text = \"me\" \n",
    "        intervals [4]:\n",
    "            xmin = 0.26 \n",
    "            xmax = 0.38 \n",
    "            text = \"show\" \n",
    "        intervals [5]:\n",
    "            xmin = 0.38 \n",
    "            xmax = 0.49 \n",
    "            text = \"you\" \n",
    "        intervals [6]:\n",
    "            xmin = 0.49 \n",
    "            xmax = 0.62 \n",
    "            text = \"how\" \n",
    "        intervals [7]:\n",
    "            xmin = 0.62 \n",
    "            xmax = 0.74 \n",
    "            text = \"they\" \n",
    "        intervals [8]:\n",
    "            xmin = 0.74 \n",
    "            xmax = 1.14 \n",
    "            text = \"work\" \n",
    "        intervals [9]:\n",
    "            xmin = 1.14 \n",
    "            xmax = 1.16 \n",
    "            text = \"\" \n",
    "    \"\"\"\n",
    "import re\n",
    "point = {}\n",
    "aligns = []\n",
    "# sr // 1000\n",
    "for l in mfa.split('\\n'):\n",
    "    m1 = re.search(r'xmin = (?P<s>[0-9\\.]+)', l)\n",
    "    m2 = re.search(r'xmax = (?P<s>[0-9\\.]+)', l)\n",
    "    m3 = re.search(r'text = (?P<s>\\\".*\\\")', l)\n",
    "    if m1 is not None:\n",
    "        point['x0'] = float(m1.group('s')) * sr\n",
    "    if m2 is not None:\n",
    "        point['x1'] = float(m2.group('s')) * sr\n",
    "    if m3 is not None:\n",
    "        point['w'] = m3.group('s').strip('\"')\n",
    "    if 'x0' in point and 'x1' in point and 'w' in point:\n",
    "        aligns.append(point)\n",
    "        point = dict()\n",
    "aligns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fa4d7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.style.use('seaborn')\n",
    "def print_segments(wav, aligns, steps, preds):\n",
    "    xpadding = 0\n",
    "    ypadding = 0.03\n",
    "    texttop = 0.18\n",
    "    offtop = 0.05\n",
    "    textbot = 0.18\n",
    "    offbot = 0\n",
    "    offarr = -0.01\n",
    "    font = 28\n",
    "    margin = 250\n",
    "    def ratio(x):\n",
    "        return (x + 1) * 4 * 10 * sr // 1000 - 1\n",
    "\n",
    "    # translation\n",
    "    T = steps.size(-1)\n",
    "    steps = steps.squeeze(0)\n",
    "    preds = preds.squeeze(0)\n",
    "    next_steps = steps.roll(-1, dims=0)\n",
    "    r_bound_trans = torch.arange(T)[(steps != next_steps)].tolist()\n",
    "    l_bound_trans = [0] + r_bound_trans\n",
    "    \n",
    "    # merge subwords\n",
    "    wordinfo = []\n",
    "    queue = []\n",
    "    end = 0\n",
    "    preds = preds.tolist() + [tgt_dict.index(\"\\u2581\")]\n",
    "    for i, idx in enumerate(preds):        \n",
    "        w = src_dict.string([idx])\n",
    "        if \"\\u2581\" in w and i > 0:\n",
    "            word = src_dict.string(queue, \"sentencepiece\")\n",
    "            start = end\n",
    "            end = r_bound_trans[i - 1]\n",
    "            wordinfo += [{\n",
    "                \"w\": word, \"l\": start, \"r\": end\n",
    "            }]\n",
    "            queue = []\n",
    "        queue += [idx]\n",
    "\n",
    "    # drawing\n",
    "    fig = plt.figure(figsize=(12, 8), dpi=100)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(wav.squeeze().cpu().numpy())\n",
    "    wav_max = wav.max().item()\n",
    "    wav_min = wav.min().item()\n",
    "    ax.hlines(wav_max, colors=\"black\", xmin=0, xmax=ratio(T)+xpadding)\n",
    "    ax.hlines(wav_min, colors=\"black\", xmin=0, xmax=ratio(T)+xpadding)\n",
    "    \n",
    "    top_units = texttop\n",
    "    mid_units = wav_max - wav_min\n",
    "    bot_units = len(wordinfo) * textbot + ypadding\n",
    "    tot_units = top_units + mid_units + bot_units\n",
    "    \n",
    "    prev = 0\n",
    "    for i, point in enumerate(aligns):\n",
    "        if len(point['w']) == 0:\n",
    "            continue\n",
    "        x0 = max(prev + margin, point['x0'])\n",
    "        prev = x1 = point['x1']\n",
    "        w = point['w']\n",
    "        ax.axvspan(x0, x1, alpha=0.1, color=\"red\", ymin=bot_units / tot_units, ymax=(bot_units + mid_units) / tot_units)\n",
    "        ax.annotate(w, (x0, wav_max + offtop), ha=\"left\", fontsize=font)\n",
    "        \n",
    "    for i, d in enumerate(wordinfo):\n",
    "        x0 = ratio(d[\"l\"])\n",
    "        x1 = ratio(d[\"r\"])\n",
    "        w = d[\"w\"]\n",
    "            \n",
    "        ax.annotate(w, (0, wav_min + offbot - textbot*(i+1)), ha=\"right\", fontsize=font, rotation=0)\n",
    "        # read arrow\n",
    "        ax.arrow(\n",
    "            x0, wav_min + offarr - textbot*(i),\n",
    "            x1 - x0, 0,\n",
    "            width=0.015, head_width=0.08, head_length=200, length_includes_head=True,\n",
    "            overhang=0.5,\n",
    "            color=\"r\", zorder=2)\n",
    "        # write arrow\n",
    "        ax.arrow(\n",
    "            x1, wav_min + offarr - textbot*(i),\n",
    "            0, -textbot,\n",
    "            width=55, head_width=400, head_length=0.05, length_includes_head=True,\n",
    "            overhang=0.5,\n",
    "            color=\"b\", zorder=2.5)        \n",
    "\n",
    "    xticks = np.array([200 * i for i in range((T+1) * 40 // 200)])\n",
    "    plt.xticks(xticks * sr / 1000, xticks, fontsize=font*0.9)\n",
    "    ax.set_xlabel(\"Time (ms)\", fontsize=font*0.9)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_ylim(wav_min - bot_units, wav_max + texttop)\n",
    "    ax.set_xlim(0, wav.size(-1)+xpadding)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(\"policy.pdf\", bbox_inches='tight', pad_inches=0.05)\n",
    "\n",
    "\n",
    "print_segments(wav, aligns, cif_steps, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db08b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(wav[:,44799:46719], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b382d03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dict.index('.')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7915ed25",
   "metadata": {},
   "source": [
    "0   1     2         3    4    5        6     7  8   9 10  11   12       13     14\n",
    "▁We ▁know ▁that ▁money ▁is ▁very ▁important , ▁go al s ▁are ▁very ▁important .\n",
    "0      1     2    3     4     5      6       7  8   9   10  11     12     13    14\n",
    "▁Wir ▁wissen , ▁dass ▁Geld ▁sehr ▁wichtig ▁ist , ▁Ziel e ▁sind ▁sehr ▁wichtig ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99169ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.post_process_prediction(\n",
    "    hypo_tokens=asr_target[0].cpu(),\n",
    "    src_str=None,\n",
    "    alignment=None,\n",
    "    align_dict=None,\n",
    "    tgt_dict=tgt_dict,\n",
    "    remove_bpe=None, #\"sentencepiece\",\n",
    "    extra_symbols_to_ignore=get_symbols_to_strip_from_output(generator),\n",
    ")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc0d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.post_process_prediction(\n",
    "    hypo_tokens=translations[0][0][\"tokens\"].int().cpu(),\n",
    "    src_str=None,\n",
    "    alignment=None,\n",
    "    align_dict=None,\n",
    "    tgt_dict=tgt_dict,\n",
    "    remove_bpe=None, #\"sentencepiece\",\n",
    "    extra_symbols_to_ignore=get_symbols_to_strip_from_output(generator),\n",
    ")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8324bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ctc_logits = extra[\"ctc_logits\"][0]\n",
    "encoder_mask = extra[\"encoder_padding_mask\"][0]\n",
    "states = best_alignment(\n",
    "    ctc_logits.log_softmax(-1).transpose(0, 1),\n",
    "    target,\n",
    "    (~encoder_mask).sum(-1),\n",
    "    target.ne(1).sum(-1),\n",
    "    blank=0,\n",
    "    as_labels=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a6cfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.style.use('seaborn')\n",
    "def print_segments(wav, states, labels, steps, preds, align):\n",
    "    xpadding = 4200\n",
    "    ypadding = 0\n",
    "    texttop = 0.25\n",
    "    offtop = 0.05\n",
    "    textbot = 0.25\n",
    "    offbot = 0\n",
    "    offarr = -0.01\n",
    "    font = 20\n",
    "    def ratio(x):\n",
    "        return (x + 1) * 4 * 10 * sr // 1000 - 1\n",
    "\n",
    "    # transcriptions\n",
    "    states = states.squeeze(0)\n",
    "    labels = labels.squeeze(0)\n",
    "    T = states.size(-1)\n",
    "\n",
    "    blanks = states % 2 == 0    \n",
    "    tgt_idx = states.div(2, rounding_mode='floor')\n",
    "    tgt_idx = tgt_idx.masked_fill(blanks, -1)\n",
    "    next_id = tgt_idx.roll(-1, dims=0)\n",
    "    prev_id = tgt_idx.roll(1, dims=0)\n",
    "\n",
    "    l_bound = torch.arange(T)[(tgt_idx != prev_id) & (~blanks)].tolist()\n",
    "    r_bound = torch.arange(T)[(tgt_idx != next_id) & (~blanks)].tolist()\n",
    "\n",
    "    # translation\n",
    "    steps = steps.squeeze(0)\n",
    "    preds = preds.squeeze(0)\n",
    "    next_steps = steps.roll(-1, dims=0)\n",
    "    r_bound_trans = torch.arange(T)[(steps != next_steps)].tolist()\n",
    "    l_bound_trans = [0] + r_bound_trans\n",
    "\n",
    "    # drawing\n",
    "    fig = plt.figure(figsize=(12, 8), dpi=100)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(wav.squeeze().cpu().numpy())\n",
    "    wav_max = wav.max().item()\n",
    "    wav_min = wav.min().item()\n",
    "    ax.hlines(wav_max, colors=\"black\", xmin=0, xmax=ratio(T)+xpadding)\n",
    "    ax.hlines(wav_min, colors=\"black\", xmin=0, xmax=ratio(T)+xpadding)\n",
    "    \n",
    "    top_units = texttop\n",
    "    mid_units = wav_max - wav_min\n",
    "    bot_units = len([l for l in labels if l not in [src_dict.eos(), 5]]) * textbot + ypadding\n",
    "    tot_units = top_units + mid_units + bot_units\n",
    "    \n",
    "    for i, (l, r, w) in enumerate(zip(l_bound, r_bound, labels)):\n",
    "        if idx in [src_dict.eos(), 5]:\n",
    "            break\n",
    "        x0 = ratio(l)\n",
    "        x1 = ratio(r)\n",
    "        # w = src_dict.string([idx], \"sentencepiece\")\n",
    "        ax.axvspan(x0, x1, alpha=0.1, color=\"red\", ymin=bot_units / tot_units, ymax=(bot_units + mid_units) / tot_units)\n",
    "        ax.annotate(w, (x0, wav_max + offtop), ha=\"left\", fontsize=font)\n",
    "        print(w, f\"{x0}:{x1}\")\n",
    "        \n",
    "    for i, (l, r, idx) in enumerate(zip(l_bound_trans, r_bound_trans, preds)):\n",
    "        if idx in [src_dict.eos(), 5]:\n",
    "            break\n",
    "        x0 = ratio(l)\n",
    "        x1 = ratio(r)\n",
    "        w = src_dict.string([idx], \"sentencepiece\")\n",
    "        ax.annotate(w, (0, wav_min + offbot - textbot*(i+1)), ha=\"right\", fontsize=font, rotation=0)\n",
    "        ax.arrow(\n",
    "            x0, wav_min + offarr - textbot*(i),\n",
    "            x1 - x0, 0,\n",
    "            width=0.03, head_width=0.1, head_length=400, length_includes_head=True, color=\"r\", zorder=2)\n",
    "        ax.arrow(\n",
    "            x1, wav_min + offarr - textbot*(i),\n",
    "            0, -textbot,\n",
    "            width=200, head_width=600, head_length=0.05, length_includes_head=True, color=\"b\", zorder=2.5)\n",
    "        \n",
    "\n",
    "    xticks = ax.get_xticks()\n",
    "    plt.xticks(xticks, (xticks * 1000 / sr).astype(int), fontsize=font*0.9)\n",
    "    ax.set_xlabel(\"Time (ms)\", fontsize=font*0.9)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_ylim(wav_min - bot_units, wav_max + texttop)\n",
    "    ax.set_xlim(0, wav.size(-1)+xpadding)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(\"policy.pdf\", bbox_inches='tight', pad_inches=0.05)\n",
    "\n",
    "\n",
    "align = [\n",
    "    (0, 0), (1, 1), (2, 3), (3, 4), (4, 7), (5, 5), (6, 6), (7, 8),\n",
    "    (8, 9), (9, 9), (10, 10), (11, 11), (12, 12), (13, 13),# (14, 14)\n",
    "]\n",
    "print_segments(wav, states, asr_target, cif_steps, target, align)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577dca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ee8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "states // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4147bb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8), dpi=100)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(states.squeeze(0).cpu().numpy() // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcac07ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_boundary(wav, states.div(2, rounding_mode='floor'), (states % 2 == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b6e838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04a13f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "data = {}\n",
    "with open(\"mustc_de-results/cif_de_align_ctc0_3_lat0_0/instances.log\", \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        d = json.loads(line)\n",
    "        data[i] = {\n",
    "            \"prediction\": d[\"prediction\"],\n",
    "            \"reference\": d[\"reference\"],\n",
    "            \"bleu\": d[\"metric\"][\"sentence_bleu\"],\n",
    "            \"AL\": d[\"metric\"][\"latency\"][\"AL\"],\n",
    "            \"reference_length\": d[\"reference_length\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a887d160",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(data, orient='index').sort_values(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047aafb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04bc0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fair]",
   "language": "python",
   "name": "conda-env-fair-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
